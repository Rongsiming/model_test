import os
from datetime import datetime
from openai import OpenAI
from tqdm import tqdm

# é…ç½®APIå®¢æˆ·ç«¯
client = OpenAI(
    api_key="sk-qckbdjlxsfwejnhghzimuwleeuvnvvvsqxvfcbmujknlsopm",
    base_url="https://api.siliconflow.cn/v1",
)

def load_answers(file_path):
    """åŠ è½½ç­”æ¡ˆæ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # æå–é—®é¢˜IDå’Œç­”æ¡ˆ
    import re
    answers_dict = {}
    qa_blocks = re.findall(r'Q(\d+):(.*?)(?=Q\d+:|$)', content, re.DOTALL)

    for q_id, answer in qa_blocks:
        answers_dict[q_id.strip()] = answer.strip()

    return answers_dict


def evaluate_answer(reference_answer, test_answer):
    """ä½¿ç”¨å¤§æ¨¡å‹è¯„ä¼°ç­”æ¡ˆ"""
    prompt = f"""
    ä½œä¸ºä¸€ä¸ªä¸“ä¸šè¯„ä¼°å‘˜ï¼Œè¯·æ¯”è¾ƒå‚è€ƒç­”æ¡ˆå’Œå¾…æµ‹ç­”æ¡ˆï¼Œå¹¶ä»ä»¥ä¸‹å››ä¸ªæ–¹é¢å¯¹å¾…æµ‹ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ï¼ˆæ»¡åˆ†ä¸º10åˆ†ï¼‰ï¼š

    1. è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›ï¼šè¯­è¨€æµç•…æ€§ã€è¯­æ³•å‡†ç¡®æ€§ã€è¡¨è¾¾æ¸…æ™°åº¦
    2. æ¨ç†èƒ½åŠ›ï¼šé€»è¾‘æ€§ã€æ¨ç†æ·±åº¦ã€è®ºè¯è´¨é‡
    3. å›ç­”å‡†ç¡®æ€§ï¼šå†…å®¹æ­£ç¡®æ€§ã€å…¨é¢æ€§ã€ç›¸å…³æ€§
    4. å›ç­”æ•ˆç‡ï¼šå›ç­”ç®€æ´åº¦ã€è¦ç‚¹æŠŠæ¡ã€æ— å†—ä½™å†…å®¹

    å‚è€ƒç­”æ¡ˆï¼ˆæ»¡åˆ†10åˆ†ï¼‰ï¼š
    {reference_answer}

    å¾…æµ‹ç­”æ¡ˆï¼š
    {test_answer}

    è¯·åœ¨è¯„åˆ†åç”¨1-2æ®µè¯ç®€è¦è¯´æ˜è¯„åˆ†ç†ç”±ï¼Œæœ€åç»™å‡ºæ€»ä½“è¯„åˆ†ï¼ˆå››é¡¹å¹³å‡åˆ†ï¼‰ã€‚

    è¾“å‡ºæ ¼å¼ï¼š
    è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›ï¼šåˆ†æ•°
    æ¨ç†èƒ½åŠ›ï¼šåˆ†æ•°
    å›ç­”å‡†ç¡®æ€§ï¼šåˆ†æ•°
    å›ç­”æ•ˆç‡ï¼šåˆ†æ•°
    è¯„åˆ†ç†ç”±ï¼šç†ç”±è¯´æ˜
    æ€»ä½“è¯„åˆ†ï¼šå¹³å‡åˆ†
    """

    response = client.chat.completions.create(
        model="deepseek-ai/DeepSeek-R1",
        messages=[
            {"role": "system", "content": "æ‚¨æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¨¡å‹è¯„ä¼°ç³»ç»Ÿï¼Œè´Ÿè´£è¯„ä¼°AIæ¨¡å‹å›ç­”çš„è´¨é‡ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=1000
    )

    return response.choices[0].message.content


def main():
    # æ–‡ä»¶è·¯å¾„
    reference_file = r"./test_model_answer/deepseek-R1_answer.txt"
    test_file =r"./test_model_answer/DeepSeek-R1-Distill-Qwen-14B_answer.txt"
    # æå–æµ‹è¯•æ¨¡å‹åç§°
    test_model_name = os.path.basename(test_file).split('_')[0]
    output_file = f"./evaluation/{test_model_name}_evaluation.txt"

    # åŠ è½½ç­”æ¡ˆ
    print(f"ğŸ“š åŠ è½½å‚è€ƒç­”æ¡ˆï¼š{reference_file}")
    reference_answers = load_answers(reference_file)

    print(f"ğŸ“ åŠ è½½å¾…æµ‹ç­”æ¡ˆï¼š{test_file}")
    test_answers = load_answers(test_file)

    # æ£€æŸ¥é—®é¢˜åŒ¹é…
    common_questions = set(reference_answers.keys()) & set(test_answers.keys())
    print(f"ğŸ” æ‰¾åˆ° {len(common_questions)} ä¸ªå…±æœ‰é—®é¢˜")

    # åˆ›å»ºè¯„ä¼°æŠ¥å‘Šå¤´éƒ¨
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# {test_model_name} è¯„ä¼°æŠ¥å‘Š\n\n")
        f.write(f"è¯„ä¼°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"å‚è€ƒæ¨¡å‹: {os.path.basename(reference_file).split('_')[0]}\n")
        f.write(f"å¾…æµ‹æ¨¡å‹: {test_model_name}\n")
        f.write(f"è¯„ä¼°é—®é¢˜æ•°é‡: {len(common_questions)}\n\n")
        f.write("## è¯„ä¼°ç»“æœæ‘˜è¦\n\n")
        f.write("| è¯„ä¼°ç»´åº¦ | å¹³å‡åˆ† |\n")
        f.write("|---------|-------|\n")
        f.write("| è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ› | å¾…è®¡ç®— |\n")
        f.write("| æ¨ç†èƒ½åŠ› | å¾…è®¡ç®— |\n")
        f.write("| å›ç­”å‡†ç¡®æ€§ | å¾…è®¡ç®— |\n")
        f.write("| å›ç­”æ•ˆç‡ | å¾…è®¡ç®— |\n")
        f.write("| **æ€»ä½“è¯„åˆ†** | **å¾…è®¡ç®—** |\n\n")
        f.write("## è¯¦ç»†è¯„ä¼°ç»“æœ\n\n")

    # åˆå§‹åŒ–åˆ†æ•°ç»Ÿè®¡
    total_scores = {
        "è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›": 0,
        "æ¨ç†èƒ½åŠ›": 0,
        "å›ç­”å‡†ç¡®æ€§": 0,
        "å›ç­”æ•ˆç‡": 0,
        "æ€»ä½“è¯„åˆ†": 0
    }

    # é€é¢˜è¯„ä¼°
    for q_id in tqdm(sorted(common_questions, key=int), desc="è¯„ä¼°è¿›åº¦"):
        ref_answer = reference_answers[q_id]
        test_answer = test_answers[q_id]

        # è°ƒç”¨APIè¯„ä¼°
        try:
            evaluation = evaluate_answer(ref_answer, test_answer)

            # è§£æè¯„åˆ†
            import re
            nlp_score = float(re.search(r'è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›ï¼š(\d+\.?\d*)', evaluation).group(1))
            reasoning_score = float(re.search(r'æ¨ç†èƒ½åŠ›ï¼š(\d+\.?\d*)', evaluation).group(1))
            accuracy_score = float(re.search(r'å›ç­”å‡†ç¡®æ€§ï¼š(\d+\.?\d*)', evaluation).group(1))
            efficiency_score = float(re.search(r'å›ç­”æ•ˆç‡ï¼š(\d+\.?\d*)', evaluation).group(1))
            total_score = float(re.search(r'æ€»ä½“è¯„åˆ†ï¼š(\d+\.?\d*)', evaluation).group(1))

            # ç´¯åŠ åˆ†æ•°
            total_scores["è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›"] += nlp_score
            total_scores["æ¨ç†èƒ½åŠ›"] += reasoning_score
            total_scores["å›ç­”å‡†ç¡®æ€§"] += accuracy_score
            total_scores["å›ç­”æ•ˆç‡"] += efficiency_score
            total_scores["æ€»ä½“è¯„åˆ†"] += total_score

            # å°†è¯„ä¼°ç»“æœå†™å…¥æ–‡ä»¶
            with open(output_file, 'a', encoding='utf-8') as f:
                f.write(f"### Q{q_id}\n\n")
                f.write("#### è¯„ä¼°ç»“æœ\n\n")
                f.write(f"{evaluation}\n\n")
                f.write("---\n\n")

        except Exception as e:
            print(f"è¯„ä¼°é—®é¢˜ Q{q_id} æ—¶å‡ºé”™: {str(e)}")
            with open(output_file, 'a', encoding='utf-8') as f:
                f.write(f"### Q{q_id} - è¯„ä¼°å¤±è´¥\n\n")
                f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n\n")
                f.write("---\n\n")

    # è®¡ç®—å¹³å‡åˆ†
    question_count = len(common_questions)
    avg_scores = {k: v / question_count for k, v in total_scores.items()}

    # æ›´æ–°è¯„ä¼°æŠ¥å‘Šæ‘˜è¦
    with open(output_file, 'r', encoding='utf-8') as f:
        report = f.read()

    report = report.replace("è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ› | å¾…è®¡ç®—", f"è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ› | {avg_scores['è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›']:.2f}")
    report = report.replace("æ¨ç†èƒ½åŠ› | å¾…è®¡ç®—", f"æ¨ç†èƒ½åŠ› | {avg_scores['æ¨ç†èƒ½åŠ›']:.2f}")
    report = report.replace("å›ç­”å‡†ç¡®æ€§ | å¾…è®¡ç®—", f"å›ç­”å‡†ç¡®æ€§ | {avg_scores['å›ç­”å‡†ç¡®æ€§']:.2f}")
    report = report.replace("å›ç­”æ•ˆç‡ | å¾…è®¡ç®—", f"å›ç­”æ•ˆç‡ | {avg_scores['å›ç­”æ•ˆç‡']:.2f}")
    report = report.replace("**æ€»ä½“è¯„åˆ†** | **å¾…è®¡ç®—**", f"**æ€»ä½“è¯„åˆ†** | **{avg_scores['æ€»ä½“è¯„åˆ†']:.2f}**")

    # æ·»åŠ æ€»ç»“
    conclusion = f"""
## è¯„ä¼°æ€»ç»“

{test_model_name} åœ¨ä¸å‚è€ƒæ¨¡å‹çš„æ¯”è¾ƒä¸­è¡¨ç°å¦‚ä¸‹ï¼š

1. **è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›**: {avg_scores['è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›']:.2f}/10
   - è¯­è¨€æµç•…æ€§ã€è¯­æ³•å‡†ç¡®æ€§ã€è¡¨è¾¾æ¸…æ™°åº¦çš„æ•´ä½“è¯„ä»·

2. **æ¨ç†èƒ½åŠ›**: {avg_scores['æ¨ç†èƒ½åŠ›']:.2f}/10
   - é€»è¾‘æ€§ã€æ¨ç†æ·±åº¦ã€è®ºè¯è´¨é‡çš„æ•´ä½“è¯„ä»·

3. **å›ç­”å‡†ç¡®æ€§**: {avg_scores['å›ç­”å‡†ç¡®æ€§']:.2f}/10
   - å†…å®¹æ­£ç¡®æ€§ã€å…¨é¢æ€§ã€ç›¸å…³æ€§çš„æ•´ä½“è¯„ä»·

4. **å›ç­”æ•ˆç‡**: {avg_scores['å›ç­”æ•ˆç‡']:.2f}/10
   - å›ç­”ç®€æ´åº¦ã€è¦ç‚¹æŠŠæ¡ã€æ— å†—ä½™å†…å®¹çš„æ•´ä½“è¯„ä»·

**ç»¼åˆè¯„åˆ†**: {avg_scores['æ€»ä½“è¯„åˆ†']:.2f}/10

è¯„ä¼°å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

    report += conclusion

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"âœ… è¯„ä¼°å®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜è‡³ {output_file}")
    print(f"ğŸ“Š æ€»ä½“è¯„åˆ†: {avg_scores['æ€»ä½“è¯„åˆ†']:.2f}/10")


if __name__ == "__main__":
    try:
        print("ğŸš€ å¼€å§‹æ¨¡å‹è¯„ä¼°æµç¨‹")
        main()
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {str(e)}")
        with open("evaluation_error.log", "a") as log:
            log.write(f"[{datetime.now()}] {str(e)}\n")